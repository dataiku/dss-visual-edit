{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":""},{"location":"#EditableEventSourced.EditableEventSourced","title":"<code>EditableEventSourced</code>","text":"<p>This class provides CRUD methods to make a dataset editable using the Event Sourcing pattern.</p> <p>Edits are stored in a separate dataset called the editlog. The source dataset is never changed. Both the source dataset and the editlog are used to compute the edited state.</p> Source code in <code>EditableEventSourced.py</code> <pre><code>class EditableEventSourced:\n\"\"\"\n    This class provides CRUD methods to make a dataset editable using the Event Sourcing pattern.\n\n    Edits are stored in a separate dataset called the editlog. The source dataset is never changed. Both the source dataset and the editlog are used to compute the edited state.\n    \"\"\"\n\n    def __save_custom_fields__(self, dataset_name):\n        settings = self.project.get_dataset(dataset_name).get_settings()\n        settings.custom_fields[\"original_ds\"] = self.original_ds_name\n        settings.custom_fields[\"editlog_ds\"] = self.editlog_ds_name\n        settings.custom_fields[\"primary_keys\"] = self.primary_keys\n        settings.custom_fields[\"editable_column_names\"] = self.editable_column_names\n        if self.webapp_url:\n            settings.custom_fields[\"webapp_url\"] = self.webapp_url\n        settings.save()\n\n    def __init_webapp_url__(self):\n        try:\n            webapp_id = find_webapp_id(self.original_ds_name)\n            webapp_name = sub(\n                r\"[\\W_]+\", \"-\", get_webapp_json(webapp_id).get(\"name\").lower()\n            )\n            self.webapp_url = (\n                f\"/projects/{self.project_key}/webapps/{webapp_id}_{webapp_name}/edit\"\n            )\n            self.webapp_url_public = f\"/public-webapps/{self.project_key}/{webapp_id}/\"\n        except:\n            self.webapp_url = None\n            self.webapp_url_public = \"/\"\n\n    def __setup_editlog__(self):\n        editlog_ds_creator = DSSManagedDatasetCreationHelper(\n            self.project, self.editlog_ds_name\n        )\n        if editlog_ds_creator.already_exists():\n            logging.debug(\"Found editlog\")\n            self.editlog_ds = Dataset(self.editlog_ds_name, self.project_key)\n            editlog_df = self.get_editlog_df()\n            if editlog_df.empty:\n                # Make sure that the dataset's configuration is valid by writing an empty dataframe.\n                # (The editlog dataset might already exist and have a schema, but its configuration might be invalid, for instance when the project was exported to a bundle and deployed to automation, and when using a SQL connection: the dataset exists but no table was created.)\n                write_empty_editlog(self.editlog_ds)\n        else:\n            logging.debug(\"No editlog found, creating it...\")\n            editlog_ds_creator.with_store_into(connection=self.__connection_name__)\n            editlog_ds_creator.create()\n            self.editlog_ds = Dataset(self.editlog_ds_name, self.project_key)\n            editlog_ds_schema = [\n                # not using date type, in case the editlog is CSV\n                {\"name\": \"date\", \"type\": \"string\", \"meaning\": \"DateSource\"},\n                {\"name\": \"user\", \"type\": \"string\", \"meaning\": \"Text\"},\n                # action can be \"update\", \"create\", or \"delete\"; currently it's ignored by the pivot method\n                {\"name\": \"action\", \"type\": \"string\", \"meaning\": \"Text\"},\n                {\"name\": \"key\", \"type\": \"string\", \"meaning\": \"Text\"},\n                {\"name\": \"column_name\", \"type\": \"string\", \"meaning\": \"Text\"},\n                {\"name\": \"value\", \"type\": \"string\", \"meaning\": \"Text\"},\n            ]\n            self.editlog_ds.write_schema(editlog_ds_schema)\n            write_empty_editlog(self.editlog_ds)\n            logging.debug(\"Done.\")\n\n        self.editlog_columns = self.editlog_ds.get_config().get(\"schema\").get(\"columns\")\n\n        # make sure that editlog has the right custom field values\n        self.__save_custom_fields__(self.editlog_ds_name)\n\n    def __setup_editlog_downstream__(self):\n        editlog_pivoted_ds_creator = DSSManagedDatasetCreationHelper(\n            self.project, self.editlog_pivoted_ds_name\n        )\n        if editlog_pivoted_ds_creator.already_exists():\n            logging.debug(\"Found editlog pivoted\")\n            unused_variable = None\n        else:\n            logging.debug(\"No editlog pivoted found, creating it...\")\n            editlog_pivoted_ds_creator.with_store_into(\n                connection=self.__connection_name__\n            )\n            editlog_pivoted_ds_creator.create()\n            self.editlog_pivoted_ds = Dataset(\n                self.editlog_pivoted_ds_name, self.project_key\n            )\n            logging.debug(\"Done.\")\n\n        pivot_recipe_name = \"compute_\" + self.editlog_pivoted_ds_name\n        pivot_recipe_creator = DSSRecipeCreator(\n            \"CustomCode_pivot-editlog\", pivot_recipe_name, self.project\n        )\n        if recipe_already_exists(pivot_recipe_name, self.project):\n            logging.debug(\"Found recipe to create editlog pivoted\")\n            pivot_recipe = self.project.get_recipe(pivot_recipe_name)\n        else:\n            logging.debug(\"No recipe to create editlog pivoted, creating it...\")\n            pivot_recipe = pivot_recipe_creator.create()\n            pivot_settings = pivot_recipe.get_settings()\n            pivot_settings.add_input(\"editlog\", self.editlog_ds_name)\n            pivot_settings.add_output(\"editlog_pivoted\", self.editlog_pivoted_ds_name)\n            pivot_settings.custom_fields[\"webapp_url\"] = self.webapp_url\n            pivot_settings.save()\n            logging.debug(\"Done.\")\n\n        edited_ds_creator = DSSManagedDatasetCreationHelper(\n            self.project, self.edited_ds_name\n        )\n        if edited_ds_creator.already_exists():\n            logging.debug(\"Found edited dataset\")\n            self.edited_ds = Dataset(self.edited_ds_name, self.project_key)\n        else:\n            logging.debug(\"No edited dataset found, creating it...\")\n            edited_ds_creator.with_store_into(connection=self.__connection_name__)\n            edited_ds_creator.create()\n            self.edited_ds = Dataset(self.edited_ds_name, self.project_key)\n            logging.debug(\"Done.\")\n\n        merge_recipe_name = \"compute_\" + self.edited_ds_name\n        merge_recipe_creator = DSSRecipeCreator(\n            \"CustomCode_merge-edits\", merge_recipe_name, self.project\n        )\n        if recipe_already_exists(merge_recipe_name, self.project):\n            logging.debug(\"Found recipe to create edited dataset\")\n            merge_recipe = self.project.get_recipe(merge_recipe_name)\n        else:\n            logging.debug(\"No recipe to create edited dataset, creating it...\")\n            merge_recipe = merge_recipe_creator.create()\n            merge_settings = merge_recipe.get_settings()\n            merge_settings.add_input(\"original\", self.original_ds_name)\n            merge_settings.add_input(\"editlog_pivoted\", self.editlog_pivoted_ds_name)\n            merge_settings.add_output(\"edited\", self.edited_ds_name)\n            merge_settings.custom_fields[\"webapp_url\"] = self.webapp_url\n            merge_settings.save()\n            logging.debug(\"Done.\")\n\n    def __init__(\n        self,\n        original_ds_name,\n        primary_keys,\n        editable_column_names=None,\n        linked_records=None,\n        editschema_manual=None,\n        project_key=None,\n        editschema=None,\n        authorized_users=None,\n    ):\n        self.original_ds_name = original_ds_name\n        if project_key is None:\n            self.project_key = getenv(\"DKU_CURRENT_PROJECT_KEY\")\n        else:\n            self.project_key = project_key\n        self.__init_webapp_url__()\n        client = api_client()\n        self.project = client.get_project(self.project_key)\n        self.original_ds = Dataset(self.original_ds_name, self.project_key)\n        self.schema_columns = self.original_ds.get_config().get(\"schema\").get(\"columns\")\n\n        self.editlog_ds_name = self.original_ds_name + \"_editlog\"\n        self.editlog_pivoted_ds_name = self.editlog_ds_name + \"_pivoted\"\n        self.edited_ds_name = self.original_ds_name + \"_edited\"\n\n        self.__connection_name__ = (\n            self.original_ds.get_config().get(\"params\").get(\"connection\")\n        )\n        if self.__connection_name__ == None:\n            self.__connection_name__ = \"filesystem_managed\"\n\n        self.primary_keys = primary_keys\n        if editable_column_names:\n            self.editable_column_names = editable_column_names\n\n        # For each linked record, add linked dataset/dataframe as attribute\n        self.linked_records = linked_records\n        if linked_records:\n            if len(self.linked_records) &gt; 0:\n                self.linked_records_df = DataFrame(data=self.linked_records).set_index(\n                    \"name\"\n                )\n                for linked_record in self.linked_records:\n                    linked_ds_name = linked_record[\"ds_name\"]\n                    linked_ds = Dataset(linked_ds_name, self.project_key)\n                    # Get the connection type of the linked dataset\n                    connection_name = (\n                        linked_ds.get_config().get(\"params\").get(\"connection\")\n                    )\n                    if connection_name:\n                        connection_type = (\n                            client.get_connection(connection_name).get_info().get_type()\n                        )\n                    else:\n                        connection_type = \"\"\n                    # Get the number of records in the linked dataset\n                    count_records = None\n                    try:\n                        metrics = self.project.get_dataset(\n                            linked_ds_name\n                        ).compute_metrics(metric_ids=[\"records:COUNT_RECORDS\"])[\n                            \"result\"\n                        ][\n                            \"computed\"\n                        ]\n                        for m in metrics:\n                            if m[\"metric\"][\"metricType\"] == \"COUNT_RECORDS\":\n                                count_records = int(m[\"value\"])\n                    except:\n                        pass\n\n                    # If the linked dataset is on an SQL connection and if it has more than 1000 records, load it as a DatasetSQL object\n                    if \"SQL\" in connection_type or \"snowflake\" in connection_type:\n                        if count_records is not None and count_records &lt;= 1000:\n                            logging.debug(\n                                f\"\"\"Loading linked dataset \"{linked_ds_name}\" in memory since it has less than 1000 records\"\"\"\n                            )\n                            linked_record[\"df\"] = linked_ds.get_dataframe()\n                        else:\n                            logging.debug(\n                                f\"\"\"Loading linked dataset \"{linked_ds_name}\" as a DatasetSQL object since it has more than 1000 records or an unknown number of records\"\"\"\n                            )\n                            linked_record[\"ds\"] = DatasetSQL(\n                                linked_ds_name, self.project_key\n                            )\n                    else:\n                        logging.debug(\n                            f\"\"\"Loading linked dataset \"{linked_ds_name}\" in memory since it isn't on an SQL connection\"\"\"\n                        )\n                        if count_records is None:\n                            logging.warning(\n                                f\"Unknown number of records for linked dataset {linked_ds_name}\"\n                            )\n                        elif count_records &gt; 1000:\n                            logging.warning(\n                                f\"Linked dataset {linked_ds_name} has {count_records} records \u2014 capping at 1,000 rows to avoid memory issues\"\n                            )\n                        # get the first 1000 rows of the dataset\n                        linked_record[\"df\"] = linked_ds.get_dataframe(\n                            sampling=\"head\", limit=1000\n                        )\n\n        self.editschema_manual = editschema_manual\n\n        if editschema:\n            self.primary_keys = get_primary_keys(editschema)\n            self.editable_column_names = get_editable_column_names(editschema)\n            self.editschema_manual = editschema\n        if self.editschema_manual:\n            self.editschema_manual_df = DataFrame(\n                data=self.editschema_manual\n            ).set_index(\"name\")\n        else:\n            self.editschema_manual_df = DataFrame(\n                data={}\n            )  # this will be an empty dataframe\n\n        self.authorized_users = authorized_users\n\n        self.display_column_names = get_display_column_names(\n            self.schema_columns, self.primary_keys, self.editable_column_names\n        )\n\n        # make sure that original dataset has up-to-date custom fields (editlog and datasets/recipes that follow may not - TODO: change this?)\n        self.__save_custom_fields__(self.original_ds_name)\n        self.__setup_editlog__()\n        self.__setup_editlog_downstream__()\n\n    def get_original_df(self):\n\"\"\"Get original data without edits\"\"\"\n        return get_original_df(self.original_ds)\n\n    def get_editlog_df(self):\n        return get_editlog_df(self.editlog_ds)\n\n    def empty_editlog(self):\n        self.editlog_ds.spec_item[\"appendMode\"] = False\n        write_empty_editlog(self.editlog_ds)\n\n    def get_edited_df_indexed(self):\n        return self.get_edited_df().set_index(self.primary_keys)\n\n    def get_edited_df(self):\n\"\"\"Get original data with edited values\"\"\"\n        return merge_edits_from_log_pivoted_df(\n            self.original_ds, self.get_edited_cells_df()\n        )\n\n    def get_edited_cells_df_indexed(self):\n        return self.get_edited_cells_df().set_index(self.primary_keys)\n\n    def get_edited_cells_df(self) -&gt; DataFrame:\n\"\"\"Get only rows and columns that were edited\"\"\"\n        return pivot_editlog(\n            self.editlog_ds, self.primary_keys, self.editable_column_names\n        )\n\n    def get_row(self, primary_keys):\n\"\"\"\n        Read a row that was created, updated or deleted (as indicated by the editlog)\n\n        Params:\n        - primary_keys: dictionary containing values for all primary keys defined in the initial data editing setup; the set of values must be unique. Example:\n            ```python\n            {\n                \"key1\": \"cat\",\n                \"key2\": \"2022-12-21\",\n            }\n            ```\n\n        Returns: single-row dataframe containing the values of editable columns.\n\n        Notes:\n        - If some rows of the dataset were created, then by definition all columns are editable (including primary keys) .\n        - If no row was created, editable columns are those defined in the initial data editing setup.\n        \"\"\"\n        key = get_key_values_from_dict(primary_keys, self.primary_keys)\n        # TODO: implementation can be optimized, so that we only load one row of the original dataset, and only load rows of the editlog that match the provided primary key values\n        # TODO: read row that was not edited too! This can be done via Dataiku API\n        return self.get_edited_cells_df_indexed().loc[key]\n\n    def __log_edit__(self, key, column, value, action=\"update\"):\n        # if the type of column_name is a boolean, make sure we read it correctly\n        for col in self.schema_columns:\n            if col[\"name\"] == column:\n                if type(value) == str and col.get(\"type\") == \"boolean\":\n                    if value == \"\":\n                        value = None\n                    else:\n                        value = str(loads(value.lower()))\n                break\n\n        # store value as a string, unless it's None\n        if value != None:\n            value_string = str(value)\n        else:\n            value_string = value\n\n        user_identifier = get_user_identifier()\n        if self.authorized_users and not user_identifier in self.authorized_users:\n            info = \"Unauthorized\"\n        else:\n            if column in self.editable_column_names or action == \"delete\":\n                # add to the editlog\n                self.editlog_ds.spec_item[\"appendMode\"] = True\n                edit_data = {\n                    \"key\": [str(key)],\n                    \"column_name\": [column],\n                    \"value\": [value_string],\n                    \"date\": [datetime.now(timezone(\"UTC\")).isoformat()],\n                    \"user\": [user_identifier],\n                }\n                if \"action\" in [col[\"name\"] for col in self.editlog_columns]:\n                    edit_data.update({\"action\": [action]})\n                self.editlog_ds.write_dataframe(DataFrame(data=edit_data))\n                info = f\"\"\"Updated column {column} where {self.primary_keys} is {key}. New value: {value}.\"\"\"\n\n            else:\n                info = f\"\"\"{column} isn't an editable column\"\"\"\n\n        logging.info(info)\n        return info\n\n    def create_row(self, primary_keys, column_values):\n\"\"\"\n        Create a new row.\n\n        Params:\n        - primary_keys: dictionary containing values for all primary keys (the set of values must be unique). Example:\n            ```python\n            {\n                \"id\": \"My new unique id\"\n            }\n            ```\n        - column_values: dictionary containing values for all other columns. Example:\n            ```python\n            {\n                \"col1\": \"hey\",\n                \"col2\": 42,\n                \"col3\": true\n            }\n            ```\n\n        Note: this method doesn't implement data validation / it doesn't check that the values are allowed for the specified columns.\n        \"\"\"\n        key = get_key_values_from_dict(primary_keys, self.primary_keys)\n        for col in column_values.keys():\n            self.__log_edit__(\n                key=key, column=col, value=column_values.get(col), action=\"create\"\n            )\n        return \"Created row\"\n\n    def update_row(self, primary_keys, column, value):\n\"\"\"\n        Update a row\n\n        Params:\n        - primary_keys: dictionary containing primary key(s) value(s) that identify the row to update (see get_row method)\n        - column: name of the column to update\n        - value: value to set for the cell identified by key and column\n        ```\n\n        Note: this method doesn't implement data validation / it doesn't check that the value is allowed for the specified column.\n        \"\"\"\n        key = get_key_values_from_dict(primary_keys, self.primary_keys)\n        return self.__log_edit__(key, column, value, action=\"update\")\n\n    def delete_row(self, primary_keys):\n\"\"\"\n        Delete a row\n\n        Params:\n        - primary_keys: dictionary containing primary key(s) value(s) that identify the row to delete (see get_row method)\n        \"\"\"\n        key = get_key_values_from_dict(primary_keys, self.primary_keys)\n        self.__log_edit__(key, None, None, action=\"delete\")\n        return f\"\"\"Deleted row\"\"\"\n</code></pre>"},{"location":"#EditableEventSourced.EditableEventSourced.create_row","title":"<code>create_row(primary_keys, column_values)</code>","text":"<p>Create a new row.</p> <ul> <li>primary_keys: dictionary containing values for all primary keys (the set of values must be unique). Example:     <code>python     {         \"id\": \"My new unique id\"     }</code></li> <li>column_values: dictionary containing values for all other columns. Example:     <code>python     {         \"col1\": \"hey\",         \"col2\": 42,         \"col3\": true     }</code></li> </ul> <p>Note: this method doesn't implement data validation / it doesn't check that the values are allowed for the specified columns.</p> Source code in <code>EditableEventSourced.py</code> <pre><code>def create_row(self, primary_keys, column_values):\n\"\"\"\n    Create a new row.\n\n    Params:\n    - primary_keys: dictionary containing values for all primary keys (the set of values must be unique). Example:\n        ```python\n        {\n            \"id\": \"My new unique id\"\n        }\n        ```\n    - column_values: dictionary containing values for all other columns. Example:\n        ```python\n        {\n            \"col1\": \"hey\",\n            \"col2\": 42,\n            \"col3\": true\n        }\n        ```\n\n    Note: this method doesn't implement data validation / it doesn't check that the values are allowed for the specified columns.\n    \"\"\"\n    key = get_key_values_from_dict(primary_keys, self.primary_keys)\n    for col in column_values.keys():\n        self.__log_edit__(\n            key=key, column=col, value=column_values.get(col), action=\"create\"\n        )\n    return \"Created row\"\n</code></pre>"},{"location":"#EditableEventSourced.EditableEventSourced.delete_row","title":"<code>delete_row(primary_keys)</code>","text":"<p>Delete a row</p> <ul> <li>primary_keys: dictionary containing primary key(s) value(s) that identify the row to delete (see get_row method)</li> </ul> Source code in <code>EditableEventSourced.py</code> <pre><code>def delete_row(self, primary_keys):\n\"\"\"\n    Delete a row\n\n    Params:\n    - primary_keys: dictionary containing primary key(s) value(s) that identify the row to delete (see get_row method)\n    \"\"\"\n    key = get_key_values_from_dict(primary_keys, self.primary_keys)\n    self.__log_edit__(key, None, None, action=\"delete\")\n    return f\"\"\"Deleted row\"\"\"\n</code></pre>"},{"location":"#EditableEventSourced.EditableEventSourced.get_edited_cells_df","title":"<code>get_edited_cells_df()</code>","text":"<p>Get only rows and columns that were edited</p> Source code in <code>EditableEventSourced.py</code> <pre><code>def get_edited_cells_df(self) -&gt; DataFrame:\n\"\"\"Get only rows and columns that were edited\"\"\"\n    return pivot_editlog(\n        self.editlog_ds, self.primary_keys, self.editable_column_names\n    )\n</code></pre>"},{"location":"#EditableEventSourced.EditableEventSourced.get_edited_df","title":"<code>get_edited_df()</code>","text":"<p>Get original data with edited values</p> Source code in <code>EditableEventSourced.py</code> <pre><code>def get_edited_df(self):\n\"\"\"Get original data with edited values\"\"\"\n    return merge_edits_from_log_pivoted_df(\n        self.original_ds, self.get_edited_cells_df()\n    )\n</code></pre>"},{"location":"#EditableEventSourced.EditableEventSourced.get_original_df","title":"<code>get_original_df()</code>","text":"<p>Get original data without edits</p> Source code in <code>EditableEventSourced.py</code> <pre><code>def get_original_df(self):\n\"\"\"Get original data without edits\"\"\"\n    return get_original_df(self.original_ds)\n</code></pre>"},{"location":"#EditableEventSourced.EditableEventSourced.get_row","title":"<code>get_row(primary_keys)</code>","text":"<p>Read a row that was created, updated or deleted (as indicated by the editlog)</p> <ul> <li>primary_keys: dictionary containing values for all primary keys defined in the initial data editing setup; the set of values must be unique. Example:     <code>python     {         \"key1\": \"cat\",         \"key2\": \"2022-12-21\",     }</code></li> </ul> <p>Notes: - If some rows of the dataset were created, then by definition all columns are editable (including primary keys) . - If no row was created, editable columns are those defined in the initial data editing setup.</p> Source code in <code>EditableEventSourced.py</code> <pre><code>def get_row(self, primary_keys):\n\"\"\"\n    Read a row that was created, updated or deleted (as indicated by the editlog)\n\n    Params:\n    - primary_keys: dictionary containing values for all primary keys defined in the initial data editing setup; the set of values must be unique. Example:\n        ```python\n        {\n            \"key1\": \"cat\",\n            \"key2\": \"2022-12-21\",\n        }\n        ```\n\n    Returns: single-row dataframe containing the values of editable columns.\n\n    Notes:\n    - If some rows of the dataset were created, then by definition all columns are editable (including primary keys) .\n    - If no row was created, editable columns are those defined in the initial data editing setup.\n    \"\"\"\n    key = get_key_values_from_dict(primary_keys, self.primary_keys)\n    # TODO: implementation can be optimized, so that we only load one row of the original dataset, and only load rows of the editlog that match the provided primary key values\n    # TODO: read row that was not edited too! This can be done via Dataiku API\n    return self.get_edited_cells_df_indexed().loc[key]\n</code></pre>"},{"location":"#EditableEventSourced.EditableEventSourced.update_row","title":"<code>update_row(primary_keys, column, value)</code>","text":"<p>Update a row</p> <ul> <li>primary_keys: dictionary containing primary key(s) value(s) that identify the row to update (see get_row method)</li> <li>column: name of the column to update</li> <li>value: value to set for the cell identified by key and column ```</li> </ul> <p>Note: this method doesn't implement data validation / it doesn't check that the value is allowed for the specified column.</p> Source code in <code>EditableEventSourced.py</code> <pre><code>def update_row(self, primary_keys, column, value):\n\"\"\"\n    Update a row\n\n    Params:\n    - primary_keys: dictionary containing primary key(s) value(s) that identify the row to update (see get_row method)\n    - column: name of the column to update\n    - value: value to set for the cell identified by key and column\n    ```\n\n    Note: this method doesn't implement data validation / it doesn't check that the value is allowed for the specified column.\n    \"\"\"\n    key = get_key_values_from_dict(primary_keys, self.primary_keys)\n    return self.__log_edit__(key, column, value, action=\"update\")\n</code></pre>"}]}