# Validating machine-generated data

## Use case description

We want business users (aka end-users) to validate machine-generated data and make corrections as needed, based on their domain expertise. From a business perspective, there are two sub use cases: we may use the human-reviewed, machine-generated data...

* for mass corrections or enrichment of source data;
* as input to an operational process.

Machine-generated data would be stored in the output dataset of an existing data pipeline. Each row would correspond to an item to validate. Columns would include:

* primary keys;
* machine-generated columns, whose values would change if the pipeline or its algorithms change;
* display-only columns, whose values would help the end-user figure out how to validate/edit/provide feedback.

Instead of exporting this dataset to Excel, we want end-users to access a web interface to validate and correct the data. In addition to the above columns, we would want 2 feedback columns: one to mark rows as valid (via checkboxes) and one to write comments.

## Special behavior of the validation column

The webapp’s backend implements special behavior when a cell from a column named "Validated" or "Reviewed" is edited: values of all editable columns from the same row are logged (even if they weren’t edited).

This allows the _editlog_ to include not just the information that the row is valid, but also the actual values that were validated. This is particularly useful when those values were generated by an algorithm, because they may change if the algorithm changes.

As a result, there will be no missing value in the machine-generated and human-reviewed columns that are present in the _edits_ dataset, for rows marked as valid.

## How-to

You must be familiar with the initial [How to Use guide](https://www.dataiku.com/product/plugins/visual-edit/#how-to-use) before following the steps below.

* **Add feedback columns to the dataset to review**: this can be done via code in the existing data pipeline, or with an additional Prepare recipe, as columns with missing values to serve as placeholders in the webapp.
* **When creating a Visual Edit webapp**: make sure to select all machine-generated columns and feedback columns as editable.
* **When using the webapp**: you would review values in generated columns (mark as valid, or edit values and add notes when necessary) and fill in missing values.
* **When building the Flow and defining the _update source_ scenario**: you would typically want to notify end-users via email if there is new data to review.
* **Test with IT**: share the _edits_ dataset with IT for them to propagate or leverage edits in other IT systems; columns of this dataset include primary keys, machine-generated and human-reviewed columns, a boolean validation column, and additional human feedback columns.

## Next

* [Building a complete application to test with end-users](build-complete-application)
* [Deploying to production](deploy)
