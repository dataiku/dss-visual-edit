# Reviewing machine-generated data | Plugin: Visual Edit | Dataiku

## Use case description

We want business users (aka end-users) to review machine-generated data and make corrections as needed, based on their domain expertise. From a business perspective, there are two sub use cases: we may use the human-reviewed, machine-generated data...

* for mass corrections or enrichment of source data;
* as input to an operational process.

Machine-generated data would be stored in the output dataset of an existing data pipeline. Each row would correspond to an item to review. Columns would include:

* primary keys;
* machine-generated columns, whose values would change if the pipeline or its algorithms change;
* display-only columns, whose values would help the end-user figure out how to review/edit/provide feedback.

Instead of exporting this dataset to Excel, we want end-users to access a web interface to review and correct the data. In addition to the above columns, we would want feedback columns to mark rows as “Reviewed” (via checkboxes) and to write comments.

## Special behavior of the Reviewed column

The webapp’s backend implements special behavior when a cell from a column named “Reviewed” is edited: values of all editable columns from the same row are logged (even if they weren’t edited).

This allows the _editlog_ to include not just the information that the row was reviewed, but also the actual values that were reviewed. This is particularly useful when those values were generated by an algorithm, because they may change if the algorithm changes.

As a result, there will be no missing value in the machine-generated and human-reviewed columns that are present in the _edits_ dataset, for rows marked as Reviewed.

## How-to

You must be familiar with the getting started guide and how to use the plugin to make corrections on source data.

* **Add feedback columns to the dataset to review**: this can be done via code in the existing data pipeline, or with an additional Prepare recipe, as columns with missing values to serve as placeholders in the webapp.
* **When creating a Visual Edit webapp**: make sure to select all machine-generated columns and feedback columns as editable.
* **When using the webapp**: you would review values in generated columns (mark as reviewed, or edit values and add notes when necessary) and fill in missing values.
* **When building the Flow and defining the _update source_ scenario**: you would typically want to notify end-users via email if there is new data to review.
* **Test with IT**: share the _edits_ dataset with IT for them to propagate or leverage edits in other IT systems (see the sub use cases mentioned at the beginning of this document); columns of this dataset include primary keys, machine-generated and human-reviewed columns, a boolean Reviewed column, and additional human feedback columns.

## Next

* If you haven't already, check out the guide to [deploy your project in production](deploy).
* If you need to customize the webapp's front-end, see the [introduction to Visual Edit's CRUD Python API](https://github.com/dataiku/dss-visual-edit/blob/master/docs/CRUD_example_usage.ipynb) and examples of [low-code webapp customizations with Dash](dash-examples).
* If you want to learn more about the plugin, you can also check out the [FAQ](faq).
